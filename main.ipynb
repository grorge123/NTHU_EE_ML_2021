{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMj55YDKG6ch",
    "outputId": "fc40ecc9-4756-48b1-d5c6-c169a8b453b2"
   },
   "outputs": [],
   "source": [
    "tr_path = 'deal_train.csv'  # path to training data\n",
    "tt_path = 'deal_test.csv'   # path to te|sting data\n",
    "se_path = 'season.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylim(0.0, 1.)\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0zlpIp9ANJRU"
   },
   "outputs": [],
   "source": [
    "tr_sz = 0\n",
    "dv_sz = 0\n",
    "class empDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=False):\n",
    "        self.mode = mode\n",
    "        global tr_sz\n",
    "        global dv_sz\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r', encoding=\"Big5\") as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array([list(map(float,i)) for i in data[1:]]).astype(float)\n",
    "        self.idx = data[:,2]\n",
    "        if not target_only:\n",
    "            feats = list(range(4,46))\n",
    "        else:\n",
    "            feats = list(range(4,46))\n",
    "        if mode == 'test':\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            target = data[:, 3]\n",
    "            data = data[:, feats]\n",
    "            \n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 < 7]\n",
    "#             elif mode == 'valid':\n",
    "#                 indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 >= 7]\n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.LongTensor(target[indices])\n",
    "        \n",
    "        self.dim = self.data.shape[1]\n",
    "        if mode == 'train':\n",
    "            tr_sz = len(self.data)\n",
    "        elif mode == 'dev':\n",
    "            dv_sz = len(self.data)\n",
    "        print('Finished reading the {} set of Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev', 'valid']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index], self.idx[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hlhLk5t6MBX3"
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = empDataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=1.0)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,2),\n",
    "        )\n",
    "        self.net.apply(init_weights)\n",
    "        self.criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "def train(tr_set, dv_set, model, config, device, tr_sz, dv_sz):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "    global best_acc\n",
    "    epoch = 0\n",
    "    model_path = './model.ckpt'\n",
    "    loss_record = {\"train\":[], \"dev\":[]}\n",
    "    while epoch < n_epochs:\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_loss = 0.0\n",
    "        model.train()                           # set model to training mode\n",
    "        for inputs, labels in tr_set:                     # iterate through the dataloader\n",
    "            inputs, labels = inputs.to(device), labels.to(device)   # move data to device (cpu/cuda)\n",
    "            outputs = model(inputs)                     # forward pass (compute output)\n",
    "#             print(outputs, labels, inputs)\n",
    "            batch_loss = model.cal_loss(outputs, labels)  # compute loss\n",
    "            _, train_pred = torch.max(outputs, 1) \n",
    "            batch_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
    "            train_loss += batch_loss.item()\n",
    "        loss_record[\"train\"].append(train_loss/len(tr_set))\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dv_set:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                batch_loss = model.cal_loss(outputs, labels) \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "\n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += batch_loss.item()\n",
    "            loss_record[\"dev\"].append(val_loss/len(dv_set))\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, n_epochs, train_acc/tr_sz, train_loss/len(tr_set), val_acc/dv_sz, val_loss/len(dv_set)\n",
    "            ))\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/dv_sz))\n",
    "\n",
    "        epoch += 1\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return val_loss, loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = True                 # TODO: Using 40 states & 2 tested_positive features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 300,                # maximum number of epochs\n",
    "    'batch_size': 256,               # mini-batch size for dataloader\n",
    "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.0001,                 # learning rate of SGD\n",
    "#         'weight_decay':0.005,\n",
    "        'momentum': 0.9              # momentum for SGD\n",
    "    },\n",
    "    'early_stop': 1000,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNrYBMmePLKm",
    "outputId": "fcd4f175-4f7e-4306-f33c-5f8285f11dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of Dataset (10075 samples found, each dim = 42)\n",
      "Finished reading the dev set of Dataset (4317 samples found, each dim = 42)\n",
      "Finished reading the test set of Dataset (3739 samples found, each dim = 42)\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
    "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "# va_set = prep_dataloader(tr_path, 'valid', config['batch_size'], target_only=target_only)\n",
    "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FHylSirLP9oh"
   },
   "outputs": [],
   "source": [
    "model = Classifier(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrEbUxazQAAZ",
    "outputId": "f4f3bd74-2d97-4275-b69f-6609976b91f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/300] Train Acc: 0.561886 Loss: 793.600150 | Val Acc: 0.940468 loss: 7.717760\n",
      "saving model with acc 0.940\n",
      "[002/300] Train Acc: 0.939851 Loss: 4.158265 | Val Acc: 0.940468 loss: 5.025876\n",
      "[003/300] Train Acc: 0.939851 Loss: 2.077791 | Val Acc: 0.940468 loss: 1.813776\n",
      "[004/300] Train Acc: 0.940149 Loss: 0.638429 | Val Acc: 0.946491 loss: 0.210444\n",
      "saving model with acc 0.946\n",
      "[005/300] Train Acc: 0.943921 Loss: 0.216811 | Val Acc: 0.946491 loss: 0.211237\n",
      "[006/300] Train Acc: 0.943921 Loss: 0.216050 | Val Acc: 0.946491 loss: 0.211321\n",
      "[007/300] Train Acc: 0.943921 Loss: 0.214927 | Val Acc: 0.946491 loss: 0.211125\n",
      "[008/300] Train Acc: 0.943921 Loss: 0.214986 | Val Acc: 0.946491 loss: 0.210986\n",
      "[009/300] Train Acc: 0.943921 Loss: 0.217066 | Val Acc: 0.946491 loss: 0.211348\n",
      "[010/300] Train Acc: 0.943921 Loss: 0.216796 | Val Acc: 0.946491 loss: 0.211412\n",
      "[011/300] Train Acc: 0.943921 Loss: 0.215520 | Val Acc: 0.946491 loss: 0.210997\n",
      "[012/300] Train Acc: 0.943921 Loss: 0.216685 | Val Acc: 0.946491 loss: 0.214710\n",
      "[013/300] Train Acc: 0.943921 Loss: 0.216122 | Val Acc: 0.946491 loss: 0.211009\n",
      "[014/300] Train Acc: 0.943921 Loss: 0.214185 | Val Acc: 0.946491 loss: 0.210990\n",
      "[015/300] Train Acc: 0.943921 Loss: 0.215315 | Val Acc: 0.946491 loss: 0.211775\n",
      "[016/300] Train Acc: 0.943921 Loss: 0.217394 | Val Acc: 0.946491 loss: 0.213545\n",
      "[017/300] Train Acc: 0.943921 Loss: 0.217582 | Val Acc: 0.946491 loss: 0.211432\n",
      "[018/300] Train Acc: 0.943921 Loss: 0.216359 | Val Acc: 0.946491 loss: 0.211090\n",
      "[019/300] Train Acc: 0.943921 Loss: 0.217520 | Val Acc: 0.946491 loss: 0.211056\n",
      "[020/300] Train Acc: 0.943921 Loss: 0.215451 | Val Acc: 0.946491 loss: 0.211013\n",
      "[021/300] Train Acc: 0.943921 Loss: 0.215505 | Val Acc: 0.946491 loss: 0.211260\n",
      "[022/300] Train Acc: 0.943921 Loss: 0.217450 | Val Acc: 0.946491 loss: 0.211850\n",
      "[023/300] Train Acc: 0.943921 Loss: 0.216288 | Val Acc: 0.946491 loss: 0.211504\n",
      "[024/300] Train Acc: 0.943921 Loss: 0.217738 | Val Acc: 0.946491 loss: 0.211065\n",
      "[025/300] Train Acc: 0.943921 Loss: 0.216421 | Val Acc: 0.946491 loss: 0.212084\n",
      "[026/300] Train Acc: 0.943921 Loss: 0.215997 | Val Acc: 0.946491 loss: 0.211056\n",
      "[027/300] Train Acc: 0.943921 Loss: 0.216665 | Val Acc: 0.946491 loss: 0.211073\n",
      "[028/300] Train Acc: 0.943921 Loss: 0.216127 | Val Acc: 0.946491 loss: 0.212239\n",
      "[029/300] Train Acc: 0.943921 Loss: 0.214651 | Val Acc: 0.946491 loss: 0.211274\n",
      "[030/300] Train Acc: 0.943921 Loss: 0.216926 | Val Acc: 0.946491 loss: 0.211531\n",
      "[031/300] Train Acc: 0.943921 Loss: 0.217497 | Val Acc: 0.946491 loss: 0.211072\n",
      "[032/300] Train Acc: 0.943921 Loss: 0.215386 | Val Acc: 0.946491 loss: 0.211139\n",
      "[033/300] Train Acc: 0.943921 Loss: 0.216963 | Val Acc: 0.946491 loss: 0.212326\n",
      "[034/300] Train Acc: 0.943921 Loss: 0.214103 | Val Acc: 0.946491 loss: 0.213315\n",
      "[035/300] Train Acc: 0.943921 Loss: 0.215427 | Val Acc: 0.946491 loss: 0.211209\n",
      "[036/300] Train Acc: 0.943921 Loss: 0.216948 | Val Acc: 0.946491 loss: 0.211079\n",
      "[037/300] Train Acc: 0.943921 Loss: 0.216770 | Val Acc: 0.946491 loss: 0.211101\n",
      "[038/300] Train Acc: 0.943921 Loss: 0.215795 | Val Acc: 0.946491 loss: 0.214133\n",
      "[039/300] Train Acc: 0.943921 Loss: 0.218161 | Val Acc: 0.946491 loss: 0.212369\n",
      "[040/300] Train Acc: 0.943921 Loss: 0.215091 | Val Acc: 0.946491 loss: 0.211607\n",
      "[041/300] Train Acc: 0.943921 Loss: 0.215248 | Val Acc: 0.946491 loss: 0.211871\n",
      "[042/300] Train Acc: 0.943921 Loss: 0.217935 | Val Acc: 0.946491 loss: 0.211917\n",
      "[043/300] Train Acc: 0.943921 Loss: 0.215680 | Val Acc: 0.946491 loss: 0.211288\n",
      "[044/300] Train Acc: 0.943921 Loss: 0.218155 | Val Acc: 0.946491 loss: 0.212602\n",
      "[045/300] Train Acc: 0.943921 Loss: 0.214282 | Val Acc: 0.946491 loss: 0.211467\n",
      "[046/300] Train Acc: 0.943921 Loss: 0.219709 | Val Acc: 0.946491 loss: 0.211299\n",
      "[047/300] Train Acc: 0.943921 Loss: 0.216336 | Val Acc: 0.946491 loss: 0.212218\n",
      "[048/300] Train Acc: 0.943921 Loss: 0.218327 | Val Acc: 0.946491 loss: 0.211119\n",
      "[049/300] Train Acc: 0.943921 Loss: 0.216568 | Val Acc: 0.946491 loss: 0.211352\n",
      "[050/300] Train Acc: 0.943921 Loss: 0.215165 | Val Acc: 0.946491 loss: 0.211370\n",
      "[051/300] Train Acc: 0.943921 Loss: 0.217169 | Val Acc: 0.946491 loss: 0.211128\n",
      "[052/300] Train Acc: 0.943921 Loss: 0.217179 | Val Acc: 0.946491 loss: 0.211519\n",
      "[053/300] Train Acc: 0.943921 Loss: 0.214776 | Val Acc: 0.946491 loss: 0.211173\n",
      "[054/300] Train Acc: 0.943921 Loss: 0.216619 | Val Acc: 0.946491 loss: 0.212556\n",
      "[055/300] Train Acc: 0.943921 Loss: 0.216831 | Val Acc: 0.946491 loss: 0.212467\n",
      "[056/300] Train Acc: 0.943921 Loss: 0.215974 | Val Acc: 0.946491 loss: 0.211143\n",
      "[057/300] Train Acc: 0.943921 Loss: 0.218253 | Val Acc: 0.946491 loss: 0.211375\n",
      "[058/300] Train Acc: 0.943921 Loss: 0.216280 | Val Acc: 0.946491 loss: 0.211151\n",
      "[059/300] Train Acc: 0.943921 Loss: 0.214930 | Val Acc: 0.946491 loss: 0.211218\n",
      "[060/300] Train Acc: 0.943921 Loss: 0.214489 | Val Acc: 0.946491 loss: 0.211155\n",
      "[061/300] Train Acc: 0.943921 Loss: 0.218505 | Val Acc: 0.946491 loss: 0.214947\n",
      "[062/300] Train Acc: 0.943921 Loss: 0.216832 | Val Acc: 0.946491 loss: 0.211212\n",
      "[063/300] Train Acc: 0.943921 Loss: 0.217331 | Val Acc: 0.946491 loss: 0.214528\n",
      "[064/300] Train Acc: 0.943921 Loss: 0.217514 | Val Acc: 0.946491 loss: 0.211273\n",
      "[065/300] Train Acc: 0.943921 Loss: 0.216484 | Val Acc: 0.946491 loss: 0.213025\n",
      "[066/300] Train Acc: 0.943921 Loss: 0.215024 | Val Acc: 0.946491 loss: 0.211184\n",
      "[067/300] Train Acc: 0.943921 Loss: 0.215959 | Val Acc: 0.946491 loss: 0.211259\n",
      "[068/300] Train Acc: 0.943921 Loss: 0.215481 | Val Acc: 0.946491 loss: 0.211249\n",
      "[069/300] Train Acc: 0.943921 Loss: 0.214378 | Val Acc: 0.946491 loss: 0.211216\n",
      "[070/300] Train Acc: 0.943921 Loss: 0.216498 | Val Acc: 0.946491 loss: 0.211184\n",
      "[071/300] Train Acc: 0.943921 Loss: 0.214424 | Val Acc: 0.946491 loss: 0.211197\n",
      "[072/300] Train Acc: 0.943921 Loss: 0.216393 | Val Acc: 0.946491 loss: 0.211190\n",
      "[073/300] Train Acc: 0.943921 Loss: 0.213931 | Val Acc: 0.946491 loss: 0.211460\n",
      "[074/300] Train Acc: 0.943921 Loss: 0.217406 | Val Acc: 0.946491 loss: 0.211584\n",
      "[075/300] Train Acc: 0.943921 Loss: 0.216867 | Val Acc: 0.946491 loss: 0.211285\n",
      "[076/300] Train Acc: 0.943921 Loss: 0.214887 | Val Acc: 0.946491 loss: 0.211205\n",
      "[077/300] Train Acc: 0.943921 Loss: 0.218183 | Val Acc: 0.946491 loss: 0.212331\n",
      "[078/300] Train Acc: 0.943921 Loss: 0.217383 | Val Acc: 0.946491 loss: 0.211989\n",
      "[079/300] Train Acc: 0.943921 Loss: 0.218340 | Val Acc: 0.946491 loss: 0.211583\n",
      "[080/300] Train Acc: 0.943921 Loss: 0.216665 | Val Acc: 0.946491 loss: 0.211513\n",
      "[081/300] Train Acc: 0.943921 Loss: 0.216082 | Val Acc: 0.946491 loss: 0.211663\n",
      "[082/300] Train Acc: 0.943921 Loss: 0.215730 | Val Acc: 0.946491 loss: 0.211345\n",
      "[083/300] Train Acc: 0.943921 Loss: 0.216901 | Val Acc: 0.946491 loss: 0.211276\n",
      "[084/300] Train Acc: 0.943921 Loss: 0.217063 | Val Acc: 0.946491 loss: 0.212706\n",
      "[085/300] Train Acc: 0.943921 Loss: 0.217756 | Val Acc: 0.946491 loss: 0.211617\n",
      "[086/300] Train Acc: 0.943921 Loss: 0.215553 | Val Acc: 0.946491 loss: 0.211797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-089d7e5bb5d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_loss_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdv_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_sz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdv_sz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-b1acce9bd845>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(tr_set, dv_set, model, config, device, tr_sz, dv_sz)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtr_set\u001b[0m\u001b[1;33m:\u001b[0m                     \u001b[1;31m# iterate through the dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# move data to device (cpu/cuda)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;31m# forward pass (compute output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#             print(outputs, labels, inputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-de47b668dc4a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;34m''' Given input of size (batch_size x input_dim), compute output of the network '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcal_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tsao han wen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device, tr_sz, dv_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hsNO9nnXQBvP",
    "outputId": "1626def6-94c7-4a87-9447-d939f827c8eb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(model_loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8cTuQjQQOon",
    "outputId": "6bc5de07-4c5a-4e87-9ae3-d09f539c5f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to pred.csv\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w', newline='') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['PerNo', 'PerStatus'])\n",
    "        for i, p in preds:\n",
    "            writer.writerow([i,p])\n",
    "model.eval() # set the model to evaluation mode\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, idx in tt_set:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        preds.extend([[int(idx[i]), int(pred[i])]for i in range(pred.shape[0])])\n",
    "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML2021Spring - HW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
